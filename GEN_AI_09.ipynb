{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrPv+tRIiyny5ObN78Jf/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52060/Generative-AI/blob/main/GEN_AI_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "assignment-9\n",
        "\n",
        "1.(1 ponto) Design a multilayer ANN architecture to identify the hand-written digits using the Keras deep learning library. Consider the MNIST data set\n",
        "\n",
        "2.(1 ponto) Calculate the accuracy with training and testing data\n",
        "\n",
        "3.(1 ponto) Also, change the architecture by tuning no. of hidden layers, no. of hidden neurons and activation functions in hidden layer. Identify best architecture in terms of testing accuracy\n",
        "\n",
        "Tabela 1: ANN Architecture\n",
        "Layer Neurons Activation Function\n",
        "\n",
        "Hidden Layer - 1 32 relu\n",
        "\n",
        "Hidden Layer - 2 32 relu\n",
        "\n",
        "Hidden Layer - 3 32 relu\n",
        "\n",
        "Tabela 2: Training Parameters\n",
        "\n",
        "epochs batch size error metric Optimizer\n",
        "\n",
        "10 128 accuracy adadelta\n",
        "\n",
        "Dataset: MNIST\n"
      ],
      "metadata": {
        "id": "OQ1Ue3-Blkgu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1A54pcGj_G-",
        "outputId": "ed437413-f0aa-4ca9-be39-06078f800548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0868 - loss: 2.3151 - val_accuracy: 0.0987 - val_loss: 2.3068\n",
            "Epoch 2/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1009 - loss: 2.3028 - val_accuracy: 0.1149 - val_loss: 2.2935\n",
            "Epoch 3/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1212 - loss: 2.2892 - val_accuracy: 0.1336 - val_loss: 2.2804\n",
            "Epoch 4/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1391 - loss: 2.2752 - val_accuracy: 0.1524 - val_loss: 2.2672\n",
            "Epoch 5/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1623 - loss: 2.2623 - val_accuracy: 0.1762 - val_loss: 2.2534\n",
            "Epoch 6/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1832 - loss: 2.2490 - val_accuracy: 0.2049 - val_loss: 2.2390\n",
            "Epoch 7/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2088 - loss: 2.2332 - val_accuracy: 0.2324 - val_loss: 2.2239\n",
            "Epoch 8/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2313 - loss: 2.2196 - val_accuracy: 0.2529 - val_loss: 2.2082\n",
            "Epoch 9/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2533 - loss: 2.2044 - val_accuracy: 0.2713 - val_loss: 2.1919\n",
            "Epoch 10/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2703 - loss: 2.1866 - val_accuracy: 0.2898 - val_loss: 2.1751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.2821\n",
            "Testing Accuracy: 0.2898\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adadelta(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_acc:.4f}\")\n",
        "model.save(\"mnist_ann_model.h5\")"
      ]
    }
  ]
}